{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Defining the Problem and Assembling the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Identify the data\n",
    "\n",
    "a. What are you trying to predict? \n",
    "b. What will the input data be? \n",
    "c. Do you have data and labels to achieve a prediction?\n",
    "\n",
    "Hypothesis:\n",
    "1. The output can be predicted by the inputs\n",
    "2. The data is sufficiently informative to learn the relationship b/w output and input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Define the Problem\n",
    "\n",
    "What type of problem am I facing? \n",
    "\n",
    "Binary/multiclass classification? Scalar Regression? vector regression? Multiclass, multilabel classification? Clustering, Generation, or reinforcement learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Not all problems can be solved and not all problems are stationary.\n",
    "\n",
    "*Make note of seasonality and capture enough data to make the problem stationary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Machine learning can only be used to memorize patterns in data. It can only recognize what it's seen before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Choosing a Measure of Success"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To achieve success, you must measure it. What will the metrics and corresponding loss function be?\n",
    "\n",
    "1. Accuracy and binary crossentropy? (Balanced class)\n",
    "2. Recall/Precision and multiclass crossentropy? (Imbalanced Class)\n",
    "3. MAE and MSE? (Regression)\n",
    "\n",
    "You may have to define your own success metric (see Kaggle)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Deciding on an Evaluation Protocol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establish how you'll evaluate the model's ability to generalize.\n",
    "\n",
    "1. Maintain a hold-out validation set and test set (plenty of data)\n",
    "2. K-Fold Cross-validation (less data, one cycle)\n",
    "3. Iterated K-fold validation (sparse data, multiple cycles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Preparing Your Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming your model is a neural network, you'll have to prepare the data in a specific manner:\n",
    "\n",
    "1. Data formatted as tensors\n",
    "2. Data is scaled and normalized\n",
    "3. Feature Engineering for small-data problems and computational efficiency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Developing a Model That Does Better Than a Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal here is to achieve statistical power: A model that does better than the naive baseline (in a binary classification problem: Acc .5 in a regression problem MSE < Mean prediction)\n",
    "\n",
    "Remember the hypotheses in 1. They may be false.\n",
    "\n",
    "\n",
    "Assuming the hypotheses are true, make these key choices in the first working model:\n",
    "1. Last-layer activation: this constrains the output to the target you defined in the first step\n",
    "2. Loss Function : must match the problem you're trying to solve\n",
    "3. Optimization Configuration : Which optimizer and what learning rate? Just go with the defaults on rmsprop to start.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Scaling Up - Developing a model that overfits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model is one that stands at the border of underfitting and overfitting. Assuming Step 5 was done correctly, we have the established where the model is underfit. Now to find the border, we must cross it.\n",
    "\n",
    "1. Add Layers\n",
    "2. Make the layers bigger\n",
    "3. Train for more epochs\n",
    "\n",
    "Always monitor training loss and validation loss. Look for performance degradation on the validation set until overfitting is achieved.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Regularizing The Model and Tuning Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeatedly modify and evaluate the model on the *validation data* until it's as good as you can get it.\n",
    "\n",
    "Try:\n",
    "1. Dropout layers\n",
    "2. Different Architectures: add/remove layers\n",
    "3. Add L1/L2 regularization\n",
    "\n",
    "Hyperparamaters:\n",
    "1. Learning Rate\n",
    "2. Number of units in each layer\n",
    "\n",
    "Feature engineering:\n",
    "1. Add/Remove features\n",
    "2. Create new features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P.S. Fitting to the validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though the model will not be trained on the validation set, it may overfit during the tuning process as the adjustments to the model will be evaluated on validation set. This is information leakage. If the final model does not perform as well on the test set, switch to a more stringent validation protocol like iterated K-fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
