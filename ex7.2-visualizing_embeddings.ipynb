{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import plot_model\n",
    "import numpy as np\n",
    "import json\n",
    "import pydot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 2000\n",
    "max_len = 500\n",
    "INDEX_FROM=3\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(\n",
    "                                            num_words=max_features, index_from=INDEX_FROM)\n",
    "\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_len)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_len)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_id = keras.datasets.imdb.get_word_index()\n",
    "word_to_id = {k:(v+INDEX_FROM) for k,v in word_to_id.items()}\n",
    "word_to_id[\"<PAD>\"] = 0\n",
    "word_to_id[\"<START>\"] = 1\n",
    "word_to_id[\"<UNK>\"] = 2\n",
    "word_to_id[\"<NAN>\"] = 3\n",
    "\n",
    "id_to_word = {value:key for key,value in word_to_id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <START> this film was just brilliant casting location scenery story direction <UNK> really <UNK> the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same <UNK> island as myself so i loved the fact there was a real <UNK> with this film the witty <UNK> throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the <UNK> <UNK> was amazing really <UNK> at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNK> to the two little <UNK> that played the <UNK> of <UNK> and paul they were just brilliant children are often left out of the <UNK> list i think because the stars that play them all <UNK> up are such a big <UNK> for the whole film but these children are amazing and should be <UNK> for what they have done don't you think the whole story was so lovely because it was true and was <UNK> life after all that was <UNK> with us all\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(' '.join(id_to_word[id] for id in X_train[0] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = np.array([id_to_word[i] for i in range(2000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('imdb_metadata.tsv',metadata, fmt='%s', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_input = keras.Input(shape=(None,), dtype='int32', name='posts')\n",
    "embed = layers.Embedding(max_features, 128,\n",
    "                            input_length=max_len,\n",
    "                            name='embed')(review_input)\n",
    "\n",
    "conv = layers.Conv1D(32, 7, activation='relu')(embed)\n",
    "conv = layers.MaxPooling1D(5)(conv)\n",
    "conv = layers.Conv1D(32, 7, activation='relu')(conv)\n",
    "conv = layers.Flatten()(conv)\n",
    "\n",
    "\n",
    "rnn = layers.LSTM(64, return_sequences=True)(embed)\n",
    "rnn = layers.LSTM(64)(rnn)\n",
    "\n",
    "merged = layers.concatenate([conv, rnn])\n",
    "bottleneck = layers.Dense(32)(merged)\n",
    "logit = layers.Dense(1, activation='sigmoid')(bottleneck)\n",
    "\n",
    "model = keras.Model(review_input, logit)\n",
    "model.compile(optimizer='rmsprop', \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'lstm_2/TensorArrayReadV3:0' shape=(?, 64) dtype=float32>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 513s 26ms/step - loss: 0.2417 - acc: 0.9012 - val_loss: 0.2709 - val_acc: 0.8882\n"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.TensorBoard(\n",
    "    log_dir='logs',\n",
    "    histogram_freq=1)\n",
    "]\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                   epochs=1,\n",
    "                   batch_size=128,\n",
    "                   validation_split=0.2,\n",
    "                   callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = model.layers[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-7.0711384e-03, -4.5139669e-03,  6.0028746e-05, ...,\n",
       "          1.2101459e-02, -2.4987003e-02,  3.2157399e-02],\n",
       "        [-2.7048759e-02, -1.6369550e-02, -1.9355888e-02, ...,\n",
       "         -3.4533836e-02,  6.7920618e-02, -2.9828006e-02],\n",
       "        [-2.3068728e-02, -7.6845428e-04, -2.4758201e-02, ...,\n",
       "          3.2362152e-02,  7.0913816e-03,  1.8190745e-02],\n",
       "        ...,\n",
       "        [-3.6380678e-02, -1.5503711e-03,  8.0812648e-03, ...,\n",
       "         -1.6207708e-02,  1.5728373e-02, -1.1022414e-02],\n",
       "        [ 8.1493091e-03,  4.9640685e-02,  5.9767988e-02, ...,\n",
       "          3.1855866e-02,  2.3286723e-02, -2.0925509e-02],\n",
       "        [ 4.3906607e-02, -1.6708386e-03,  1.7216362e-02, ...,\n",
       "          1.8780176e-03,  3.7177466e-02, -5.5808701e-02]], dtype=float32)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('imdb_embeddings.tsv', embed.get_weights()[0], delimiter='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydot in /opt/anaconda3/envs/tensorflow/lib/python3.6/site-packages (1.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in /opt/anaconda3/envs/tensorflow/lib/python3.6/site-packages (from pydot) (2.3.0)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
